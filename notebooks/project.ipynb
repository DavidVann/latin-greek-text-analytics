{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS 5001 Project Notebook: Greek and Roman Mythology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- David Vann (dv6bq@virginia.edu)\n",
    "- DS 5001\n",
    "- 5 May 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "from eta_modules.preprocessing import Document, Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the data\n",
    "\n",
    "We start by loading in the XML files for each work and parsing them to a reasonable degree with BeautifulSoup and NLTK. \n",
    "\n",
    "Since these works are all either plays or poems/epics, the concept of a \"chapter\" or \"paragraph\" doesn't translate perfectly compared to, e.g., a novel. However, the Perseus Digital Library (where these files are sourced from) has added at least top-level divisions to break up texts. In some cases, these divisions truly exist in the text (for example, *The Iliad* is broken into 24 books); in other cases, like plays, these divisions don't seem to be directly present in the text, but are akin to something like a \"scene\". I've considered all of these largest divisions as \"chapters\".\n",
    "\n",
    "To get at something like a \"paragraph\", I used a different approach based on whether the work was a play or not:\n",
    "\n",
    "- For plays, I used each speaker section (denoted by a \"\\<sp>\" in the files) as a \"paragraph\". \n",
    "- For everything else, there wasn't a built-in tag for \"paragraph\"-type divisions, but there is a self-closing \"milestone\" tag that marks the start of a new \"card\" used on the Perseus website to denote content to be displayed on one page. Since these are self-closing, they don't actually enclose the particular block of text that I wanted to get at; instead, I replaced these with newlines and split up text based on a double newline, which seemed to give fairly satisfactory results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.path.abspath('..')\n",
    "data_dir = os.path.join(root_dir, 'data')\n",
    "output_dir = os.path.join(data_dir, 'outputs')\n",
    "\n",
    "docpaths = glob(os.path.join(data_dir, 'raw', '**', '*.xml'), recursive=True)\n",
    "\n",
    "OHCO = ['work', 'chapter', 'para', 'sent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list = []\n",
    "\n",
    "for path in docpaths:\n",
    "    doc = Document(path)\n",
    "    doc_list.append(doc)\n",
    "    \n",
    "    doc.parse_text_to_paras()\n",
    "    doc.tokenize(remove_pos_tuple=True, remove_ws=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_bag = OHCO[:1]\n",
    "chapter_bag = OHCO[:2]\n",
    "paragraph_bag = OHCO[:3]\n",
    "\n",
    "corp = Corpus(doc_list)\n",
    "corp.extract_annotate_vocab()\n",
    "corp.compute_tfidf(OHCO_level=book_bag, methods=['n', 'max', 'bool'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               n  stop     p_stem  df       idf  tfidf_n_sum  tfidf_max_sum  \\\n",
       "term_str                                                                      \n",
       "oedipus      436     0     oedipu   5  1.925999     0.853654       0.289711   \n",
       "electra      222     0    electra   5  1.925999     0.434659       0.271490   \n",
       "thou        2550     0       thou   6  1.662965     4.310846       0.263936   \n",
       "creon        216     0      creon   5  1.925999     0.422911       0.263725   \n",
       "odysseus     787     0    odysseu   7  1.440573     1.152522       0.259000   \n",
       "orestes      225     0      orest   9  1.078003     0.246571       0.257692   \n",
       "dionysus     138     0    dionysu   8  1.247928     0.175068       0.255391   \n",
       "deathless    103     0  deathless   7  1.440573     0.150838       0.254800   \n",
       "prometheus   101     0  prometheu   5  1.925999     0.197750       0.254311   \n",
       "achilles     548     0      achil   8  1.247928     0.695199       0.253800   \n",
       "\n",
       "            tfidf_bool_sum  \n",
       "term_str                    \n",
       "oedipus           0.204559  \n",
       "electra           0.202865  \n",
       "thou              0.121421  \n",
       "creon             0.164499  \n",
       "odysseus          0.191628  \n",
       "orestes           0.162370  \n",
       "dionysus          0.205215  \n",
       "deathless         0.260727  \n",
       "prometheus        0.216066  \n",
       "achilles          0.156809  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>n</th>\n      <th>stop</th>\n      <th>p_stem</th>\n      <th>df</th>\n      <th>idf</th>\n      <th>tfidf_n_sum</th>\n      <th>tfidf_max_sum</th>\n      <th>tfidf_bool_sum</th>\n    </tr>\n    <tr>\n      <th>term_str</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>oedipus</th>\n      <td>436</td>\n      <td>0</td>\n      <td>oedipu</td>\n      <td>5</td>\n      <td>1.925999</td>\n      <td>0.853654</td>\n      <td>0.289711</td>\n      <td>0.204559</td>\n    </tr>\n    <tr>\n      <th>electra</th>\n      <td>222</td>\n      <td>0</td>\n      <td>electra</td>\n      <td>5</td>\n      <td>1.925999</td>\n      <td>0.434659</td>\n      <td>0.271490</td>\n      <td>0.202865</td>\n    </tr>\n    <tr>\n      <th>thou</th>\n      <td>2550</td>\n      <td>0</td>\n      <td>thou</td>\n      <td>6</td>\n      <td>1.662965</td>\n      <td>4.310846</td>\n      <td>0.263936</td>\n      <td>0.121421</td>\n    </tr>\n    <tr>\n      <th>creon</th>\n      <td>216</td>\n      <td>0</td>\n      <td>creon</td>\n      <td>5</td>\n      <td>1.925999</td>\n      <td>0.422911</td>\n      <td>0.263725</td>\n      <td>0.164499</td>\n    </tr>\n    <tr>\n      <th>odysseus</th>\n      <td>787</td>\n      <td>0</td>\n      <td>odysseu</td>\n      <td>7</td>\n      <td>1.440573</td>\n      <td>1.152522</td>\n      <td>0.259000</td>\n      <td>0.191628</td>\n    </tr>\n    <tr>\n      <th>orestes</th>\n      <td>225</td>\n      <td>0</td>\n      <td>orest</td>\n      <td>9</td>\n      <td>1.078003</td>\n      <td>0.246571</td>\n      <td>0.257692</td>\n      <td>0.162370</td>\n    </tr>\n    <tr>\n      <th>dionysus</th>\n      <td>138</td>\n      <td>0</td>\n      <td>dionysu</td>\n      <td>8</td>\n      <td>1.247928</td>\n      <td>0.175068</td>\n      <td>0.255391</td>\n      <td>0.205215</td>\n    </tr>\n    <tr>\n      <th>deathless</th>\n      <td>103</td>\n      <td>0</td>\n      <td>deathless</td>\n      <td>7</td>\n      <td>1.440573</td>\n      <td>0.150838</td>\n      <td>0.254800</td>\n      <td>0.260727</td>\n    </tr>\n    <tr>\n      <th>prometheus</th>\n      <td>101</td>\n      <td>0</td>\n      <td>prometheu</td>\n      <td>5</td>\n      <td>1.925999</td>\n      <td>0.197750</td>\n      <td>0.254311</td>\n      <td>0.216066</td>\n    </tr>\n    <tr>\n      <th>achilles</th>\n      <td>548</td>\n      <td>0</td>\n      <td>achil</td>\n      <td>8</td>\n      <td>1.247928</td>\n      <td>0.695199</td>\n      <td>0.253800</td>\n      <td>0.156809</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "corp.vocab.sort_values('tfidf_max_sum', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corp.save_tables(os.path.join(output_dir, 'corpus'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python392jvsc74a57bd06494f67c0c6cf60fb8c82a3cd67c9027a88bb126664f19bac7f5ad6badb395e4",
   "display_name": "Python 3.9.2 64-bit ('ds': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "metadata": {
   "interpreter": {
    "hash": "6494f67c0c6cf60fb8c82a3cd67c9027a88bb126664f19bac7f5ad6badb395e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}